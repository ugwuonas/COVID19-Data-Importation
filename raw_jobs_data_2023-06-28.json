{"status": "OK", "request_id": "8656cd1f-53ce-4bdb-9d70-3403713eac32", "parameters": {"query": "data engineer, canada", "page": 1, "num_pages": 1, "date_posted": "today"}, "data": [{"employer_name": "Procore", "employer_logo": "https://play-lh.googleusercontent.com/7HFT3wvmk_2r_8HSydOUBJ7nzUnyzjA2gCOSGEIe5XjAikdLJke0a9n044hzqc3FcCY", "employer_website": "http://www.procore.com", "employer_company_type": "Information", "job_publisher": "Procore Technologies", "job_id": "i-LbKEY1nygAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Staff Data Engineer", "job_apply_link": "https://careers.procore.com/jobs/32767cce-c654-4423-978a-84a5f75eaef7", "job_apply_is_direct": false, "job_apply_quality_score": 0.8135, "job_description": "Job Description\n\nWhat if you could use your technology skills to develop a product that impacts the way communities\u2019 hospitals, homes, sports stadiums, and schools across the world are built? Construction impacts the lives of nearly everyone in the world, and yet it\u2019s also one of the world\u2019s least digitized industries, not to mention one of the most dangerous. That\u2019s why we\u2019re looking for a talented Staff Data Engineer to join Procore\u2019s journey to revolutionize a historically underserved industry.\n\nAs a Staff Data Engineer on Procore\u2019s Data Platform team, you\u2019ll design and code data products. You\u2019ll be part of a high-performance team of Data/Software Engineers and contribute to designing, building, testing, scaling, and maintaining data products from various source systems and streams (internal, third-party, cloud-based, etc.), according to business and technical requirements.\n\nThis position will report to our Senior Manager of Data Engineering and can be based remotely from any US location. We\u2019re looking for someone to join our team immediately.\n\nWhat you\u2019ll do:\n\u2022 Lead the design and development of data products using object-oriented analysis, design and programming skills, and design patterns\n\u2022 Maintain existing data products and develop new data products using data technologies\n\u2022 Responsible for leading the effort to continuously improve the reliability, scalability, and stability of the Procore data platform\n\u2022 Contribute to and lead the continuous improvement of the software development framework and processes by collaborating with Quality Assurance engineers\n\u2022 Implement ETL products for data matching, data cleansing, data integration, and management\n\u2022 Develop and maintain tables and data models in SQL, abstracting multiple sources and historical data across varied schemas to a format suitable for further analysis\n\u2022 Reproduce, troubleshoot, and determine the root cause of production issues\n\u2022 Deliver observable, reliable, and secure software, embracing the \u201cyou build it, you run it\u201d mentality, and focusing on automation and GitOps\n\u2022 Participate in daily standups, team meetings, sprint planning, and demo/retrospectives while working cross-functionality with other teams to drive the innovation of our products\n\nWhat we\u2019re looking for:\n\u2022 BS degree in Computer Science, a similar technical field of study, or equivalent practical experience; MS or Ph.D. degree in Computer Science or a related field is preferred\n\u2022 8+ years of experience in an Engineering position; 4+ years of experience building data products for large-scale distributed system design and data processing, including building streaming data products using Kafka, Spark, or Flink\n\u2022 Building and maintaining data warehouses products in support of BI tools (Snowflake, dbt, Tableau)\n\u2022 Building data product framework for data workflow to process large data sets and Real-Time & Batch Data Pipeline development\n\u2022 Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metrics providers ranging from advertising, web analytics, and consumer devices\n\u2022 Desire to write code daily, using Java, Python, SQL ETC, along with willingness and passion for mentoring junior engineers and performing code reviews\n\u2022 Possess familiarity with AWS-managed services for data (Glue, Athena, Data Pipeline, Flink, Spark) and Snowflake\n\u2022 Develop data catalogs and data cleanliness to ensure clarity and correctness of key business metrics\n\u2022 Strong knowledge of common algorithms, data structures, object-oriented programming, and design\n\nAdditional Information\n\nPerks & Benefits\n\nAt Procore, we invest in our employees and provide a full range of benefits and perks to help you grow and thrive. From generous paid time off and healthcare coverage to career enrichment and development programs, learn more details about what we offer and how we empower you to be your best.\n\nAbout Us\n\nProcore Technologies is building the software that builds the world. We provide cloud-based construction management software that helps clients more efficiently build skyscrapers, hospitals, retail centers, airports, housing complexes, and more. At Procore, we have worked hard to create and maintain a culture where you can own your work and are encouraged and given resources to try new ideas. Check us out on Glassdoor to see what others are saying about working at Procore.\n\nWe are an equal-opportunity employer and welcome builders of all backgrounds. We thrive in a diverse, dynamic, and inclusive environment. We do not tolerate discrimination against employees on the basis of age, color, disability, gender, gender identity or expression, marital status, national origin, political affiliation, race, religion, sexual orientation, veteran status, or any other classification protected by law.\n\nIf you'd like to stay in touch and be the first to hear about new roles at Procore, join our Talent Community.", "job_is_remote": false, "job_posted_at_timestamp": 1687901152, "job_posted_at_datetime_utc": "2023-06-27T21:25:52.000Z", "job_city": "Toronto", "job_state": "ON", "job_country": "CA", "job_latitude": 43.653225, "job_longitude": -79.38319, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=i-LbKEY1nygAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-09-25T21:46:16.000Z", "job_offer_expiration_timestamp": 1695678376, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 96, "experience_mentioned": true, "experience_preferred": true}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4", "job_naics_code": "511210", "job_naics_name": "Software Publishers"}, {"employer_name": "Egen", "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxHt31k2LgdLMGH1SVR5x1R2BhMdxgMWIbm_VA&s=0", "employer_website": null, "employer_company_type": null, "job_publisher": "LinkedIn", "job_id": "hGaJyw17rh8AAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer", "job_apply_link": "https://ca.linkedin.com/jobs/view/senior-data-engineer-at-egen-3642771305", "job_apply_is_direct": false, "job_apply_quality_score": 0.5844, "job_description": "Egen is a data engineering and cloud modernization firm helping industry-leading companies achieve digital breakthroughs and deliver for the future, today. We are catalysts for change who create digital breakthroughs at warp speed. Our team of cloud and data engineering experts are trusted by top clients in pursuit of the extraordinary. An Inc. 5000 Fastest Growing Company 7 times, and recently recognized on the Crain\u2019s Chicago Business Fast 50 list, Egen has also been recognized as a Great Place to Work 4 times.\n\nYou will join a team of insatiably curious data engineers, software architects, and product experts who never settle for \"good enough\". Our Data Engineering teams build scalable data platforms and fault-tolerant pipelines for modern analytics and AI services using Python, SQL, Linux, Bash, and AWS, GCP, or Azure data storage and warehousing services.\n\nAs a Senior Data Engineer, you will be the subject matter expert in building event-driven data pipelines, supporting & solving data integration challenges, and cloud-native data warehouse and data lake processing.\n\nResponsibilities:\n\u2022 Lead and develop passionate data engineering teams to design and develop distributed and event-driven data pipelines with cloud-native data stores such as Snowflake, Redshift, Big Query, or ADW.\n\u2022 Design, document, and lead development of end-to-end data product pipelines\n\u2022 Consult business, product, and data science teams to understand end-user requirements or analytics needs to implement the most appropriate data platform technology and scalable data engineering practices.\n\u2022 Prepare data mapping, data flow, production support, and pipeline documentation for all projects.\n\u2022 Lead data engineering and/or operations teams in delivering completeness of source system data by performing a profiling analysis and triaging issues reported in production systems.\n\u2022 Facilitate fast and efficient data migrations through a deep understanding of design, mapping, implementation, management, and support of distributed data pipelines.\n\nWhat we're looking for:\n\u2022 Minimum of Bachelor\u2019s Degree or its equivalent in Computer Science, Computer Information Systems, Information Technology and Management, Electrical Engineering or a related field.\n\u2022 You have productionized real-time data pipelines through EDA leveraging Kafka or a similar service.\n\u2022 You know what it takes to build and run resilient data pipelines in production and have experience implementing ETL/ELT to load a multi-terabyte enterprise data warehouse.\n\u2022 You have a strong understanding and exposure to data mesh principles in building modern data-driven products and platforms\n\u2022 You have a strong background in distributed data warehousing with Snowflake, Redshift, Big Query, and/or Azure Data Warehouse.\n\u2022 You have expert programming/scripting knowledge in building and managing ETL pipelines using SQL, Python, and Bash.\n\u2022 You have implemented analytics applications using multiple database technologies, such as relational, multidimensional (OLAP), key-value, document, or graph.", "job_is_remote": false, "job_posted_at_timestamp": 1687881297, "job_posted_at_datetime_utc": "2023-06-27T15:54:57.000Z", "job_city": null, "job_state": "ON", "job_country": "CA", "job_latitude": 44.038376, "job_longitude": -79.2, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=hGaJyw17rh8AAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-27T15:54:57.000Z", "job_offer_expiration_timestamp": 1690473297, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": ["Python (Programming Language)", "Django", "Microsoft Azure", "SQL", "Extract", "Transform", "Load (ETL)", "Snowflake", "Databases", "Google BigQuery", "Cloud Storage"], "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": true, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "TD", "employer_logo": "https://www.td.com/us/en/personal-banking/images/TDB_tag_white_tcm371-253361.png", "employer_website": "http://www.td.com", "employer_company_type": "Finance", "job_publisher": "LinkedIn", "job_id": "6xYf7P4bXnAAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer- EN", "job_apply_link": "https://ca.linkedin.com/jobs/view/data-engineer-en-at-td-3648823106", "job_apply_is_direct": false, "job_apply_quality_score": 0.5455, "job_description": "TD Description\n\nTell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think \"TD\" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.\n\nStay current and competitive. Carve out a career for yourself. Grow with us. Here's our story: jobs.td.com\n\nDepartment Overview\n\nBuilding a World-Class, Diverse and Inclusive Technology Team at TD\n\nWe can't afford to be boring. Neither can you. The scale and scope of what TD does may surprise you. The rapid pace of change makes it a business imperative for us to be smart and open-minded in the way we think about technology. TD's technology and business teams become more intertwined as new opportunities present themselves. This new era in banking does not equal boring. Not at TD, anyway.\n\nThe TDS Veritas Platform is the cross-asset pricing and risk management platform for TD Securities. TDS Veritas is also the strategic storage and compute infrastructure for numerous business-aligned products used by front office users as well as risk management functions in the Investment Bank. Within the wider platform team, the TDS Veritas Data Interfaces team is responsible for sourcing and curating Trade, Market Data and Reference Data information.\n\nThere's room to grow in all of it.\n\nJob Description\n\nAbout This Role\n\nWe are looking for a savvy Data Engineer (Engineer II) to join our growing team of engineers. The hire will be responsible for maintaining our current our data pipelines and be a key contributor as we design the next generation of cloud native data and analytics platform.\n\nThe ideal candidate is an experienced data pipeline builder and data wrangler who understands the Capital Markets domain and enjoys optimizing data systems and building them from the ground up. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company\u2019s data architecture to support our next generation of products and data initiatives.\n\nResponsibilities\n\u2022 Create and maintain optimal data pipeline architecture\n\u2022 Implement data products curated by our Chief Data Office, as well as custom data models for fit for use.\n\u2022 Ensure data quality and integrity across various data sources and systems to ensure data accuracy, completeness, and reliability.\n\u2022 Optimize data pipelines for performance and scalability.\n\u2022 Provide technical support to promptly resolve escalated incidents/outages.\n\u2022 Develop and document a detailed solution design, impart your subject matter expertise throughout life cycle.\n\u2022 Take business, Enterprise Architecture, system performance and development standards requirements, then develop functional, technical and user interface designs for an application and/or system.\n\u2022 Find ways to keep costs low, help come up with strategic solutions to support cost effectiveness and enhance stakeholder experience.\n\u2022 Conduct code reviews to address quality, standards compliance, reusability and ease of maintenance, Operational Readiness Reviews, and support gating and review sign-offs for solution design.\n\u2022 Ensure design leverages existing reusable components, traces back to business requirements, and that new modules are designed with reusability in mind.\n\u2022 Keep up to date with the latest industry trends and technologies related to data engineering.\n\nJob Requirements\n\nWhat can you bring to TD? Share your credentials, but your relevant experience and knowledge can be just as likely to get our attention. It helps if you have:\n\nPreferred Qualifications\n\u2022 Undergraduate Degree.\n\u2022 8+ years of relevant experience in a related field of job function.\n\u2022 Experience with: Java, Spring,\n\u2022 Some Experience to Big Data Tools such as : Hadoop, HDFS, ADLS, ADF, Spark, Kafka, Databricks, Dremio etc.\n\u2022 Experience with relational SQL and NoSQL databases, including Cassandra.\n\u2022 Experience designing production grade, scalable applications and microservices.\n\nNice to have\n\u2022 Experience in Python, Scala\n\u2022 Experience in Capital Markets\n\u2022 Experience working on Agile Teams\n\nDesired Interpersonal Skills\n\u2022 Takes great personal pride in building robust software\n\u2022 Strong sense of ownership\n\u2022 Passionate about programming and computer science\n\u2022 Enjoys working in a fast-paced environment\n\u2022 Has excellent written and verbal communication skills\n\u2022 Has strong customer focus\n\nAdditional Information\n\nJoin in on what others in TD Technology Solutions are doing:\n\u2022 Inspire a positive work environment and help champion quality, innovation, teamwork and service to the business.\n\u2022 Learn voraciously, stretch your thinking, share your knowledge and educate others.\n\u2022 Communicate and collaborate with both technical and non-technical professionals.\n\u2022 Cultivate winning relationships by building trust with business and technology partners.\n\u2022 Share our commitment to productivity, effectiveness and operational efficiency.\n\nInclusiveness\n\nAt TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.", "job_is_remote": false, "job_posted_at_timestamp": 1687886125, "job_posted_at_datetime_utc": "2023-06-27T17:15:25.000Z", "job_city": "Toronto", "job_state": "ON", "job_country": "CA", "job_latitude": 43.653225, "job_longitude": -79.38319, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=6xYf7P4bXnAAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-27T17:15:25.000Z", "job_offer_expiration_timestamp": 1690478125, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 96, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": true, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15111100", "job_onet_job_zone": "5", "job_naics_code": "522110", "job_naics_name": "Commercial Banking"}, {"employer_name": "Vretta Inc.", "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQyeAsCcN4eSejsbE0tyAfzVdiEtpW0SHqZOwTK&s=0", "employer_website": null, "employer_company_type": null, "job_publisher": "LinkedIn", "job_id": "JjDMJpYTA1UAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer", "job_apply_link": "https://ca.linkedin.com/jobs/view/data-engineer-at-vretta-inc-3648804052", "job_apply_is_direct": false, "job_apply_quality_score": 0.5844, "job_description": "Vretta is looking for a Data Engineer to join our Data and Evaluation team. This position requires excellent communication skills, creative problem solving ability, and a sound technical ability to be able to understand requirements, develop technological solutions for data analysis, collaborate with the data engineering and development team, and maintain processes that support student learning and assessment. As a member of the Data and Evaluation team at Vretta, the Data Engineer must have the attitude and energy to innovate and build solutions that support student success.\n\nResponsibilities\n\u2022 Validate technical requirements and communicate implementation strategies.\n\u2022 Develop APIs in collaboration with Instructional Designers, Data Engineers, and other members of the development and technical team to deliver projects.\n\u2022 Document APIs, especially in relation to the underlying data model.\n\u2022 Use existing code components to implement new projects.\n\u2022 Maintain and modify existing APIs.\n\u2022 Debug, test, and deploy software implementations.\n\u2022 Interact with key partners and internal users regarding timelines, technical issues, and infrastructure integration.\n\u2022 Provide recommendations for improvements in the overall development process.\n\u2022 Ensure work progress to schedule and keep (internal) customers informed of project progress.\n\u2022 Stay current with relevant research, techniques, technology, and other factors impacting the job.\n\nRequirements\n\u2022 At least two years experience in software development.\n\u2022 Undergraduate degree in Computer Science (or equivalent).\n\u2022 Experience with modern JavaScript (server-side JavaScript, package management, module loading).\n\u2022 Experience with REST APIs.\n\u2022 Strong experience writing & understanding complex SQL queries.\n\u2022 Ability to effectively communicate technical concepts to other technical staff members.\n\u2022 Superior time management skills, and the ability to prioritize tasks with minimal supervision.\n\u2022 High level of critical and logical thinking, analysis, and/or reasoning to identify underlying principles, reasons, or facts.\n\nExperience with any of the following is an asset\n\u2022 TypeScript\n\u2022 WebPack\n\u2022 MySQL, MariaDB\n\u2022 R\n\u2022 Linear Optimization\n\u2022 Statistical Techniques\n\u2022 Data modeling\n\u2022 Automated testing\n\nAbout Vretta\n\nWe have dedicated the past 13 years towards the modernization of assessment and learning experiences that have transformed educational practices for ministries of education, academic institutions, examination bodies, and training organizations around the world. Today, our team of over 100 architects, designers, technologists, psychometricians, and project ninjas support our partners transition from legacy e-assessment and learning systems to world-class technology solutions that are efficient, equitable, flexible, and drive student-success. We welcome you to join us on our mission of giving every student the opportunity to succeed in their academic lives and beyond.\n\nApplying\n\nWe look forward to hearing from you, but please note that due to the volume of applications that we usually receive for our job positions, only those shortlisted for next steps will be contacted. Vretta is committed to providing reasonable accommodations for people with disabilities. If you require an accommodation, we will work with you to meet your needs in all stages of the hiring process.\n\nTo stay in touch with Vretta and keep up-to-date on all open opportunities, follow us on LinkedIn, Facebook, and Twitter!", "job_is_remote": true, "job_posted_at_timestamp": 1687883077, "job_posted_at_datetime_utc": "2023-06-27T16:24:37.000Z", "job_city": null, "job_state": null, "job_country": "CA", "job_latitude": 56.130367, "job_longitude": -106.34677, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=JjDMJpYTA1UAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-12-24T16:24:14.000Z", "job_offer_expiration_timestamp": 1703435054, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 156, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": ["Skill Development", "Data Engineering", "Learning", "Data Analytics", "Student Success", "Data Modeling", "SQL", "MariaDB", "TypeScript", "Computer Science", "R (Programming Language)"], "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": true, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "Informa Group Plc.", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "SmartRecruiters Job Search", "job_id": "80o7y0ZJrS8AAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer", "job_apply_link": "https://jobs.smartrecruiters.com/InformaGroupPlc/743999915429829-senior-data-engineer", "job_apply_is_direct": false, "job_apply_quality_score": 0.7602, "job_description": "Company Description\n\nCurinos is the leading provider of data, technologies and insights that enable financial institutions to make better, and more profitable, data-driven decisions faster. Born out of the combination of two familiar industry powerhouses, Novantas and Informa\u2019s FBX business, Curinos brings to market a new level of industry expertise across deposits, lending and digital experience solutions and technologies.\n\nJob Description\n\nWe are looking for a Software Engineer to work on the Amplero platform. Amplero\u2019s patented technology dynamically identifies the right tone, message components, and channel preferences to improve marketing performance. This is an engineering position that works closely with Customer Success on integrating clients onto our big data platform. This entails evaluating customer requirements with respect to our platform\u2019s capabilities and implementing such requirements as needed. This role is also involved in ongoing maintenance and enhancements in support of our clients.\n\nOur engineers are part of a cross-functional engineering team that ensures each customer\u2019s ETL is working properly. This includes, but is not limited to; data ingestion, developing and maintaining pipeline components, and developing custom outbound data feeds.\n\nQualifications\n\nDesired Skills & Expertise\n\nCandidates should have the following background, skills, and qualities:\n\u2022 Programming languages\n\u2022 Java, Scala, Python\n\u2022 SQL\n\u2022 Competency with shell scripting in a Linux environment\n\u2022 Exposure to contemporary big data stacks and technologies. Typical examples include things such as Yarn, HDFS, Spark, Hadoop and Databricks, but this is not an exclusive list.\n\u2022 Solid understanding of data structures and algorithms\n\u2022 3+ years of experience is preferred\n\u2022 Some experience with production support.\n\u2022 Experience with 3rd party marking clouds (such as Salesforce) strongly desired.\n\u2022 Self\u2013discipline and willingness to learn\n\u2022 Solid verbal and written communication skills\n\u2022 Team player and ability to work well with others in an intellectually challenging environment\n\nAdditional Information\n\nWhy work at Curinos?\n\u2022 Competitive benefits, including a range of Financial, Health and Lifestyle benefits to choose from\n\u2022 Flexible working options, including home working, flexible hours and part time options, depending on the role requirements \u2013 please ask!\n\u2022 Competitive annual leave, floating holidays, volunteering days and a day off for your birthday!\n\u2022 Learning and development tools to assist with your career development\n\u2022 Work with industry leading Subject Matter Experts and specialist products\n\u2022 Regular social events and networking opportunities\n\u2022 Collaborative, supportive culture, including an active DE&I program\n\u2022 Employee Assistance Program which provides expert third-party advice on wellbeing, relationships, legal and financial matters, as well as access to counselling services\n\nApplying:\n\nWe know that sometimes the 'perfect candidate' doesn't exist, and that people can be put off applying for a job if they don't meet all the requirements. If you're excited about working for us and have relevant skills or experience, please go ahead and apply. You could be just what we need!\n\nIf you need any adjustments to support your application, such as information in alternative formats, special requirements to access our buildings or adjusted interview formats please\u202fcontact us at careers@curinos.com and we\u2019ll do everything we can to help.\n\nInclusivity at Curinos:\n\nWe believe strongly in the value of diversity and creating supportive, inclusive environments where our colleagues can succeed.\u202f As such, Curinos\u202fis proud to be an Equal Opportunity Employer.\u202fWe do not discriminate on the basis of race, color, ancestry, national origin, religion, or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other protected characteristics.", "job_is_remote": false, "job_posted_at_timestamp": 1687875342, "job_posted_at_datetime_utc": "2023-06-27T14:15:42.000Z", "job_city": "Toronto", "job_state": "ON", "job_country": "CA", "job_latitude": 43.653225, "job_longitude": -79.38319, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=80o7y0ZJrS8AAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 36, "experience_mentioned": true, "experience_preferred": true}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": false, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "Quantum World Technologies Inc.", "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTgsQ4QQa7kv786x8eRV-wQUKFOVC_DPwcQsNtr&s=0", "employer_website": null, "employer_company_type": null, "job_publisher": "LinkedIn", "job_id": "53xEfN0Z08wAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer", "job_apply_link": "https://ca.linkedin.com/jobs/view/senior-data-engineer-at-quantum-world-technologies-inc-3645989326", "job_apply_is_direct": false, "job_apply_quality_score": 0.5809, "job_description": "Role: Azure Data Engineer\n\nLocation: Toronto ,ON (Hybrid)\n\nJob Type: Fulltime\n\nRequired Skills :\n\n. Must Have 7+ Year of IT Experience in IT Field\n\n. Must have minimum 6+ year of hands-on experience on Data bricks\n\n\u2022 Primary Tech skills \u2013 Azure, Delta Lake, Databricks, Data Vault modelling for DWH, Python/pyspark\n\n\u2022 Secondary Tech skills \u2013 Azure Infra, FSLDM, Azure Synapse\n\nTechno-Managerial covering entire life cycle of data warehouse and data cloud environment with experience in building data platforms development.", "job_is_remote": false, "job_posted_at_timestamp": 1687902981, "job_posted_at_datetime_utc": "2023-06-27T21:56:21.000Z", "job_city": "Toronto", "job_state": "ON", "job_country": "CA", "job_latitude": 43.653225, "job_longitude": -79.38319, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=53xEfN0Z08wAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-27T21:56:21.000Z", "job_offer_expiration_timestamp": 1690494981, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 84, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": true, "degree_mentioned": false, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "SSTECH USA GROUP", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "LinkedIn", "job_id": "VxtzuSsowMQAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer", "job_apply_link": "https://ca.linkedin.com/jobs/view/senior-data-engineer-at-sstech-usa-group-3645664420", "job_apply_is_direct": false, "job_apply_quality_score": 0.5748, "job_description": "FULL STACK DATA ENGINEER\n\nWe are looking for an experienced Full Stack Data Engineer to join our team for building a next-generation data platform built on Data Mesh architecture/principles. The ideal candidate should have extensive hands-on experience in building a big data platform, Big Data Technologies, Data Pipelines, backend development using Python, BI/Analytics tools as well as experience with DevOps, AWS, and UI Development in Angular JS. You will be responsible for designing, developing, and maintaining our web applications and data pipelines, as well as implementing CI/CD best practices.\n\nRESPONSIBILITIES\n\u2022 Design, build, and maintain scalable and efficient data platforms using data engineering technologies such as Glue, EMR, Athena, Redshift, Lake Formation, Apache Spark, Hive, HDFS, and Trino.\n\u2022 Build/manage data pipelines, and common data-related cross-cutting concerns like data catalog, data lineage, data quality, data profiling, data discovery, metadata management\n\u2022 Develop and maintain web applications using AngularJS and Python.\n\u2022 Build/manage BI/Analytical dashboard reducing time to insight for the business stakeholders.\n\u2022 Implement CI/CD pipelines using Terraform, Jenkins, Github actions, and Gitflow.\n\u2022 Collaborate with cross-functional teams to develop and implement new features.\n\u2022 Write clean, reusable, and efficient code.\n\u2022 Participate in code reviews and ensure code quality.\n\u2022 Develop and maintain APIs using Python and ensure API security and best practices are implemented.\n\u2022 Implement SSO integration with Microsoft Azure AD using oAuth, OIDC, and SAML.\n\u2022 Implement integration with AWS Cognito for user authentication and authorization.\n\u2022 Ensure the application is optimized for maximum speed and scalability.\n\u2022 Troubleshoot and debug issues as they arise.\n\u2022 Implement DevOps best practices to ensure efficient application deployment and management.\n\u2022 Collaborate with data scientists and analysts to integrate data analytics solutions with web applications.\n\u2022 Stay up to date with emerging trends and technologies.\n\nMust have\n\u2022 8+ years of experience in similar positions\n\u2022 Hands-on Experience with data engineering technologies such as AWS Glue, EMR, Athena, Redshift, Lake Formation, Apache Spark, Apache Hive, Apache Airflow, S3FS, Apache Hudi, and Trino.\n\u2022 Extensive experience in building data pipelines using orchestration tools like Apache Airflow.\n\u2022 Hands-on experience in building cross-cutting concerns like data catalog, data lineage, data quality, data profiling, data discovery, metadata management\n\u2022 Proven experience as a Full Stack Developer with AngularJS and Python.\n\u2022 Strong understanding of web development technologies including HTML, CSS, and JavaScript.\n\u2022 Experience working with RESTful APIs and JSON.\n\u2022 Familiarity with microservices architecture.\n\u2022 Experience with core AWS technologies such as EC2, ELB, Auto Scaling, S3, EFS, Lambda, API\n\nGateway, Step Functions, Cloudwatch, VPC, Route 53, ACM\n\u2022 Hands on experience with SQL and NoSQL databases.\n\u2022 Hands experience with BI tools like Tableau, AWS QuickSight\n\u2022 Experience with Git or other version control systems.\n\u2022 Understanding of agile development methodologies.\n\u2022 Strong problem-solving skills.\n\u2022 Excellent written and verbal communication skills.\n\u2022 Ability to work independently and collaboratively in a team environment.\n\u2022 Experience with cloud platforms such as AWS.\n\u2022 Bachelor's degree in Computer Science, Engineering, or related field\n\nNice to have\n\u2022 Agile, Scrum framework 2+ years' experience on past projects\n\u2022 Knowledge of containerization technologies like Docker or Kubernetes.\n\u2022 Experience with front-end frameworks like React or Vue.js.\n\u2022 Experience with DevOps and CI/CD best practices.\n\u2022 Experience with Terraform and the AWS provider.\n\u2022 Experience with API development, security, and best practices.\n\u2022 Experience with SSO integration with Microsoft Azure AD using oAuth, OIDC, and SAML.\n\u2022 Experience with integration with AWS Cognito for user authentication and authorization", "job_is_remote": true, "job_posted_at_timestamp": 1687877866, "job_posted_at_datetime_utc": "2023-06-27T14:57:46.000Z", "job_city": "Toronto", "job_state": "ON", "job_country": "CA", "job_latitude": 43.653225, "job_longitude": -79.38319, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=VxtzuSsowMQAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-27T14:57:46.000Z", "job_offer_expiration_timestamp": 1690469866, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 96, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": true, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": 50, "job_max_salary": 73, "job_salary_currency": "USD", "job_salary_period": "HOUR", "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "Bay Street Staffing", "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSQwfo7A2kC3rtmoxgLvThZpLgS9vMKbOURB_KV&s=0", "employer_website": null, "employer_company_type": null, "job_publisher": "Recruit.net", "job_id": "vd-vqQOsItAAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer", "job_apply_link": "https://www.recruit.net/job/data-engineer-jobs/A46BA83B081C48E4", "job_apply_is_direct": false, "job_apply_quality_score": 0.4166, "job_description": "Job Description: Senior/Staff Data Engineer (Contract full-time)\n\nWe are currently hiring for a Senior/Staff Data Engineer (Contract full-time) to join our newly formed Data & Analytics Engineering team. This team is dedicated to establishing a robust data & analytics engineering foundation at scale, empowering fast data-driven decision-making for our business partners.\n\nRole Overview:\n\nAs a Data Engineer at the Senior/Staff level, you will be responsible for driving data solution architecture and implementation in an agile environment. You will work closely with our business partners and other key stakeholders to deliver high-quality data solutions.\n\nQualifications:\n\nMinimum of 8 years of software/data engineering experience, including at least 2 years of technical lead experience.\n\nStrong knowledge of data engineering best practices and data architecture patterns, such as Data Mesh and Lakehouse.\n\nProven experience in end-to-end data architecture and design, preferably with Azure technologies such as Data Factory, Databricks, Delta Lake, Synapse, Purview, and Azure DevOps.\n\nSolid understanding of data modeling fundamentals and expertise in implementing effective data governance practices, including data quality, lineage, and data discovery.\n\nExperience driving CI/CD and laC adoption to automate change management of data pipelines and infrastructure, utilizing tools like Git/GitHub, Jenkins, Terraform, and Ansible.\n\nDeep proficiency in Python and SQL, with experience using PySpark.\n\nAbility to build data exploratory interfaces using Notebooks (e.g., Databricks) and sandbox environments to enable self-service capabilities.\n\nPassion for taking ownership and applying engineering best practices in day-to-day work.\n\nSelf-starter and quick learner, always seeking opportunities to drive engineering excellence and never satisfied with the status quo.\n\nResponsibilities:\n\nIn this role, your typical day will involve:\n\nDesigning and implementing full-stack data and analytics solutions at scale to enhance analytics capabilities.\n\nIndependently shipping large and complex features and foundational improvements from start to completion, including requirements/data analysis, development, testing, and deployment.\n\nBuilding and maintaining data pipelines that ingest, clean, transform, aggregate, and serve structured and unstructured data to meet operational and analytical needs.\n\nDriving data modeling and ensuring proper data quality and integrity checks as part of data pipelines.\n\nEstablishing robust infrastructure on Azure to enable self-service data and analytics, advanced data science, and machine learning capabilities for our business users.\n\nManaging complex requirements and technical discussions with minimal oversight, providing architecture recommendations aligned with the technology roadmap and enterprise data strategy.\n\nContinuously seeking opportunities to improve data and code quality, platform performance, and scalability by introducing and implementing engineering best practices and standards.\n\nLocation: Toronto/Hybrid (2 days in office + remote)\n\nContract Duration: 12 months", "job_is_remote": false, "job_posted_at_timestamp": 1687910400, "job_posted_at_datetime_utc": "2023-06-28T00:00:00.000Z", "job_city": "Toronto", "job_state": "ON", "job_country": "CA", "job_latitude": 43.653225, "job_longitude": -79.38319, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=vd-vqQOsItAAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-28T00:00:00.000Z", "job_offer_expiration_timestamp": 1690502400, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 96, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": false, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "Altis Recruitment", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "Indeed", "job_id": "SMjekXVuMBcAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer", "job_apply_link": "https://ca.indeed.com/viewjob?jk=675b20b074d19095", "job_apply_is_direct": false, "job_apply_quality_score": 0.5853, "job_description": "Job Type\n\nContract\n\nIndustry\n\nStaffing and Recruitment\n\nLanguage\n\u2022 Work Arrangement\n\nRemote\n\nDate Posted\n\nTuesday, June 27, 2023\n\nSalary\n\u2022 per Hour\n\nSpecialization\n\nIT - Business Intelligence\n\nSecurity Clearance\n\u2022 Location\n\u2022 Opportunity Number\n\n9201\n\nJob Description\n\nAltis is hiring an internal Data Engineer to join our team for a 3 month contract! We are a remote first organization with the option to work from our any of our office locations in either Toronto or Ottawa! (for those who need to get out of the house)\n\nResponsibilities:\n\u2022 Design, develop, and implement scalable data architectures that meet the organization's current and future data requirements.\n\u2022 Collaborate with cross-functional teams to gather and understand data needs, and translate them into data architecture solutions.\n\u2022 Develop and maintain data models, data dictionaries, and data integration processes.\n\u2022 Create and optimize data pipelines to ensure efficient data extraction, transformation, and loading (ETL) processes.\n\u2022 Identify and resolve data quality issues, ensuring data accuracy and integrity.\n\u2022 Evaluate and recommend appropriate data management and analytics technologies, tools, and frameworks.\n\u2022 Perform performance tuning, optimization, and troubleshooting of data systems and pipelines and cleansing of data.\n\u2022 Develop and enforce data governance policies and best practices.\n\nQualifications:\n\u2022 Bachelor's degree in Computer Science, Engineering, or a related field. A master's degree is a plus.\n\u2022 Proven experience in both data architecture and data engineering roles, preferably in a fast-paced and data-intensive environment.\n\u2022 Strong knowledge of data modeling, data warehousing, and data integration techniques.\n\u2022 5 years\u2019 experience with MSSQL.\n\u2022 3 years\u2019 experience with ETLs such as AWS Glue or Azure Data Factory.\n\u2022 Must have worked on a data engineering projects\n\u2022 Must have been involved in digital transformations\n\u2022 Experience writing data models\n\u2022 Experience generating data marts for visual purposes\n\u2022 Experience with Kafka is an asset.\n\u2022 Strong analytical and problem-solving skills with the ability to handle complex data-related challenges.\n\u2022 Excellent communication and collaboration skills to work effectively with cross-functional teams.\n\u2022 Ability to adapt to changing priorities, work independently, and meet tight deadlines.\n\nWe\u2019re an equal opportunities employer committed to increasing diversity and inclusion in today\u2019s workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Minorities, women, LGBTQ candidates, and individuals with disabilities are encouraged to apply. If you require an accommodation, please review our accessibility policy and reach out to our accessibility officer with any questions.", "job_is_remote": false, "job_posted_at_timestamp": 1687891713, "job_posted_at_datetime_utc": "2023-06-27T18:48:33.000Z", "job_city": null, "job_state": null, "job_country": "CA", "job_latitude": 56.130367, "job_longitude": -106.34677, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=SMjekXVuMBcAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-27T19:33:05.000Z", "job_offer_expiration_timestamp": 1690486385, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 60, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "Online Business Systems", "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT_P9k-vsKWKU2Vu7IoNt8PqbAAQjjhM7HnDvhR&s=0", "employer_website": null, "employer_company_type": null, "job_publisher": "LinkedIn", "job_id": "7L4tcZzjTDEAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer", "job_apply_link": "https://ca.linkedin.com/jobs/view/data-engineer-at-online-business-systems-3642770946", "job_apply_is_direct": false, "job_apply_quality_score": 0.5931, "job_description": "We are seeking an experienced Data Engineer with expertise in ETL and BI toolsets to join our Technology Consulting team. You will work with amazing development teams on a variety of assignments with different clients. By gathering requirements, doing analysis, and consulting with clients, you will be able to lay a solid data foundation to perform robust analytics. You will have the opportunity to build your technical skills and expertise in both ETL and BI as well as expand your consulting skills. You are a team player with a true passion for data and a desire to learn and grow in your career.\n\nWhat you\u2019ll do:\n\u2022 Design ETL process and data flow from source systems to data warehouse.\n\u2022 Develop and unit test ETL processes for optimal performance and performance-tune ETL mappings and report queries.\n\u2022 Design and develop Business Intelligence solutions to meet end user demands.\n\u2022 Design physical database objects including fact tables, dimensions, staging, materialized views, and indexes.\n\nWhat we\u2019d like:\n\u2022 Ability to interact with clients and business users and analyze complex business requirements.\n\u2022 Hands-on experience in tuning ETL jobs to reduce run-time and increase efficiency through code tuning, hardware deployment, and architecture changes.\n\u2022 Experience designing and building BI visualizations to meet client needs.\n\u2022 Experience with ETL tools such as Ab Initio, Informatica, Microsoft SSIS, IBM DataStage, SAP Data Services etc.\n\u2022 Experience with BI tools such as Tableau, Power BI, and MicroStrategy.\n\u2022 Practical experience with Windows, UNIX, relational databases (Oracle, SQL Server), SQL, and/or Oracle PL/SQL.\n\u2022 Strong understanding of data warehousing architectures, core concepts, methodologies, and best practices.\n\u2022 Detail oriented with analytical and problem-solving skills to recognize and identify issues and take proper action to resolve them.\n\u2022 Experience using software development tools such as Azure DevOps, JIRA, Confluence, Source Code Management, and CI/CD pipelines is considered an asset.\n\u2022 Up to date on latest technology trends.\n\u2022 Experience with AWS, Azure and/or GCP is an asset.\n\u2022 Experience with Python is an asset.\n\u2022 Experience with AI and Machine Learning is an asset\n\nWhy Work with Us?\n\nOur story began in 1986 in Winnipeg, Canada, where our CEO grew a small team of University friends into an award-winning Digital Transformation and Cybersecurity consultancy with over 350 team members across North America and EMEA. We have the stability of a larger company but the heart of a small company, even as we continue to grow. We have been on the \u201cBest Workplaces in Canada\u201d list for the past 17 years and you\u2019ll understand why when you read what our team members say on Glassdoor (https://www.glassdoor.ca/Overview/Working-at-Online-Business-Systems-EI_IE373050.11,34.htm).\n\nWe offer a competitive compensation and benefits package as well as:\n\n\u2022 Professional Development budget and time\n\n\u2022 Tech-enablement program for home use\n\n\u2022 Career Mentor to help you grow in your career\n\n\u2022 RRSP/401K match program\n\n\u2022 Bonus programs to reward you for your accomplishments\n\n\u2022 Wellness program to keep you healthy\n\n\u2022 Opportunities to connect \u2013 book clubs, games nights, Special Interest Groups, \u201cCoffee & Code\u201d for our developer friends, Team Meetings, and much more\n\nOnline firmly believes in respect, equity, and equality and in providing EVERYONE equal opportunity to apply and succeed in their role. We are committed to creating and maintaining an inclusive and accessible environment for everyone.", "job_is_remote": true, "job_posted_at_timestamp": 1687882618, "job_posted_at_datetime_utc": "2023-06-27T16:16:58.000Z", "job_city": null, "job_state": null, "job_country": "CA", "job_latitude": 56.130367, "job_longitude": -106.34677, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer,+canada&start=0&chips=date_posted:today&schips=date_posted;today&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer,+canada&htidocid=7L4tcZzjTDEAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-27T16:16:58.000Z", "job_offer_expiration_timestamp": 1690474618, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": true, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}]}